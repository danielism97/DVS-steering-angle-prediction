{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "\n",
    "from keras import layers, regularizers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4} )\n",
    "sess = tf.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load DVS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "X = np.zeros((800, 180, 240, 2))\n",
    "for i in range(800):\n",
    "    frame_inc = cv2.imread(\"Data_DVS_superimpose/\" + str(i) + \"_inc.png\", cv2.IMREAD_GRAYSCALE)\n",
    "    frame_dec = cv2.imread(\"Data_DVS_superimpose/\" + str(i) + \"_dec.png\", cv2.IMREAD_GRAYSCALE)\n",
    "    X[i,:,:,0] = frame_inc / 255\n",
    "    X[i,:,:,1] = frame_dec / 255\n",
    "\n",
    "Y = np.zeros((800, 3))\n",
    "yvals = pd.read_excel('Data_DVS_superimpose/data_trial_new_new.xlsx',sheet_name = 'Sheet1',nrows = 400)\n",
    "y_orig = yvals.values[:,1].reshape(yvals.values[:,1].shape[0],1) # y.shape = (400,1)\n",
    "y_aug = np.absolute(y_orig - 2)\n",
    "y = np.concatenate((y_orig, y_aug), axis = 0)\n",
    "for i in range(y.shape[0]):\n",
    "    Y[i, int(y[i,0])] = 1\n",
    "    \n",
    "X_train = X[0:700, :]\n",
    "Y_train = Y[0:700, :]\n",
    "X_test = X[700: 750, :]\n",
    "Y_test = Y[700: 750, :]\n",
    "X_dev = X[750: 800, :]\n",
    "Y_dev = Y[750: 800, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load pixel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# RGB\n",
    "# X = np.zeros((800, 180, 240, 3))\n",
    "# Grayscale\n",
    "X = np.zeros((800, 180, 240, 1))\n",
    "for i in range(800):\n",
    "    # RGB\n",
    "#     img = image.load_img(\"Data_pixel/\" + str(i) + \".jpg\", target_size = (180, 240)) \n",
    "    # grayscale\n",
    "    img = image.load_img(\"Data_pixel/\" + str(i) + \".jpg\", color_mode='grayscale', target_size = (180, 240)) # grayscale\n",
    "    img_array = image.img_to_array(img)\n",
    "    X[i] = img_array / 255\n",
    "\n",
    "\n",
    "Y = np.zeros((800, 3))\n",
    "yvals = pd.read_excel('Data_DVS_superimpose/data_trial_new_new.xlsx',sheet_name = 'Sheet1',nrows = 400)\n",
    "y_orig = yvals.values[:,1].reshape(yvals.values[:,1].shape[0],1) # y.shape = (400,1)\n",
    "y_aug = np.absolute(y_orig - 2)\n",
    "y = np.concatenate((y_orig, y_aug), axis = 0)\n",
    "for i in range(y.shape[0]):\n",
    "    Y[i, int(y[i,0])] = 1\n",
    "\n",
    "X_train = X[0:700, :]\n",
    "Y_train = Y[0:700, :]\n",
    "X_test = X[700: 750, :]\n",
    "Y_test = Y[700: 750, :]\n",
    "X_dev = X[750: 800, :]\n",
    "Y_dev = Y[750: 800, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_keras(input_shape, drop_prob, lambd):\n",
    "    \"\"\"\n",
    "    Using keras to quickly prototype.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input placeholder as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    # first layer: 2@180x240 -> 6@90x120\n",
    "    X = Conv2D(6, (20,20), strides = (2,2), padding='same', kernel_regularizer=regularizers.l2(lambd), name = \"conv1\")(X_input)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = Dropout(drop_prob, noise_shape=None, seed=None)(X)\n",
    "    \n",
    "    # max pooling: 6@90x120 -> 6@45x60\n",
    "    X = MaxPooling2D((2,2), strides = (2,2), padding='valid')(X)\n",
    "    \n",
    "    # second layer: 6@45x60 -> 12@23x30\n",
    "    X = Conv2D(12, (5,5), strides = (2,2), padding='same', kernel_regularizer=regularizers.l2(lambd), name = \"conv2\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = Dropout(drop_prob, noise_shape=None, seed=None)(X)\n",
    "    \n",
    "    # third layer: 12@23x30 -> 18@12x15\n",
    "    X = Conv2D(18, (5,5), strides = (2,2), padding='same', kernel_regularizer=regularizers.l2(lambd), name = \"conv3\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = Dropout(drop_prob, noise_shape=None, seed=None)(X)\n",
    "    \n",
    "    # fourth layer: 18@12x15 -> 24@6x8\n",
    "    X = Conv2D(24, (5,5), strides = (5,5), padding='same', kernel_regularizer=regularizers.l2(lambd), name = \"conv4\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = Dropout(drop_prob, noise_shape=None, seed=None)(X)\n",
    "    \n",
    "    # flatten: 36@8x10 -> 1152\n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    # third layer: 1152 -> 64\n",
    "    X = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(lambd), name='fc1')(X)\n",
    "    \n",
    "    # fourth layer: 64 -> 3\n",
    "    X = Dense(3, activation='softmax', kernel_regularizer=regularizers.l2(lambd), name='fc2')(X)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name = \"NN_model_2_keras\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.4787 - acc: 0.9443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd7f2ec198>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "cnn_model = cnn_model_keras(X_train[0].shape, drop_prob = 0.2, lambd = 0.025)\n",
    "\n",
    "# compile the model\n",
    "cnn_model.compile(optimizer = 'adam', loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "cnn_model.fit(x = X_train, y = Y_train, epochs = 1, batch_size = X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 522us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Loss = 0.7263352108001709\n",
      "Dev Accuracy = 0.8600000023841858\n",
      "50/50 [==============================] - 0s 502us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "Loss = 0.8513526034355163\n",
      "Test Accuracy = 0.8400000023841858\n"
     ]
    }
   ],
   "source": [
    "preds = cnn_model.evaluate(x = X_dev, y = Y_dev)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Dev Accuracy = \" + str(preds[1]))\n",
    "\n",
    "preds = cnn_model.evaluate(x = X_test, y = Y_test)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))\n",
    "#cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 4ms/step\n",
      "index: 710\n",
      "predicted: [[0. 1. 0.]]\n",
      "correct: [1. 0. 0.]\n",
      "index: 716\n",
      "predicted: [[1. 0. 0.]]\n",
      "correct: [0. 0. 1.]\n",
      "index: 717\n",
      "predicted: [[0. 1. 0.]]\n",
      "correct: [0. 0. 1.]\n",
      "index: 718\n",
      "predicted: [[1. 0. 0.]]\n",
      "correct: [0. 1. 0.]\n",
      "index: 720\n",
      "predicted: [[1. 0. 0.]]\n",
      "correct: [0. 1. 0.]\n",
      "index: 747\n",
      "predicted: [[0. 1. 0.]]\n",
      "correct: [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for i in range(50):\n",
    "    pred = cnn_model.evaluate(x = X_test[i:i+1], y = Y_test[i:i+1])\n",
    "    if(pred[1] < 1):\n",
    "        y_pred = cnn_model.predict(X_test[i:i+1])\n",
    "        max_prob = np.amax(y_pred)\n",
    "        y_pred[y_pred == max_prob] = 1\n",
    "        y_pred[y_pred < max_prob] = 0\n",
    "        errors.append((i, y_pred))\n",
    "\n",
    "for i in range(len(errors)):\n",
    "    print(\"index: \" + str(700 + errors[i][0]))\n",
    "    print(\"predicted: \" + str(errors[i][1]))\n",
    "    print(\"correct: \" + str(Y_test[errors[i][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cnn_model.save('models_class/cnn_model_GPU_pixGray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model = load_model('models_class/cnn_model_GPU_pixRGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Visualisation of Kernels\n",
    "The method is to randomly initialise an input image for a kernel, and define a loss function to be the average value of output of the kernel, then train on the input image by gradient ascent to maximise the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from scipy.misc import imsave\n",
    "# filter num:  6               6                  12              18              24\n",
    "# layer name: 'activation_5', 'max_pooling2d_2', 'activation_6', 'activation_7', 'activation_8'\n",
    "\n",
    "layer_dict = dict([(layer.name, layer) for layer in cnn_model.layers])\n",
    "\n",
    "# choose layer and specific filter to visualise\n",
    "layer_name = 'max_pooling2d_2'\n",
    "filter_index = 2\n",
    "\n",
    "#\n",
    "input_img = cnn_model.inputs[0]\n",
    "\n",
    "# create a loss to maximise the activation of a layer\n",
    "layer_output = layer_dict[layer_name].output\n",
    "loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "# compute the gradient of the input picture wrt this loss\n",
    "grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "# normalization trick: we normalize the gradient\n",
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "# this function returns the loss and grads given the input picture\n",
    "iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "# initialise a random input image, and update pixel values by training\n",
    "input_img_data = np.random.random((1, 100, 100, 2))\n",
    "\n",
    "# run gradient ascent\n",
    "for i in range(20):\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    input_img_data += grads_value * 1\n",
    "    \n",
    "img = input_img_data[0,:,:,0]\n",
    "imsave('layers/%s_filter_%d.png' % (layer_name, filter_index), img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
